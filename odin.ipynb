{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Image Classification for AS\n",
    "## Import of libraries, selection of CUDA_VISIBLE_DEVICES to select gpu to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify by segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ref1pal/anaconda2/envs/mlEnv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Reshape, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from random import shuffle\n",
    "from scipy import misc\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import keras.backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.misc import imresize\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used, will be ported into separate utils.py later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getBatchGens(trainPath, validPath, batchSize, trainShuffle=True, targetSize=(128,128)):\n",
    "    datagenTrain = ImageDataGenerator(\n",
    "            shear_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            rescale=1/255,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "    datagenValid = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "    trainBatches = datagenTrain.flow_from_directory(\n",
    "            trainPath,  # this is the target directory\n",
    "            target_size=targetSize,  # all images will be resized to 197x197\n",
    "            batch_size=batchSize,\n",
    "            class_mode='binary',\n",
    "            shuffle=trainShuffle,\n",
    "            )  # since we use binary_crossentropy loss, we need binary labels\n",
    "    \"\"\"\n",
    "            save_to_dir = '/home/ref1pal/project/AS/allOkNok/examples',\n",
    "            save_format = 'jpg'\n",
    "            \"\"\"\n",
    "    \n",
    "    validBatches = datagenValid.flow_from_directory(\n",
    "            validPath,  # this is the target directory\n",
    "            target_size=targetSize,  # all images will be resized to 197x197\n",
    "            batch_size=batchSize,\n",
    "            class_mode='binary',\n",
    "            shuffle=False)  # since we use binary_crossentropy loss, we need binary labels\n",
    "    return trainBatches, validBatches\n",
    "\n",
    "class leakyBatches(object):\n",
    "    def __init__(self, gen, leak):\n",
    "        self.n = gen.n\n",
    "        self.batch_size = gen.batch_size\n",
    "        self.leak = leak\n",
    "        self.gen = gen\n",
    "        self.newGen = self.newerGen()\n",
    "        self.batch_index = self.gen.batch_index\n",
    "        self.filenames = self.gen.filenames\n",
    "    \n",
    "    def newerGen(self):\n",
    "        while True:\n",
    "            x, y_gen = next(self.gen)\n",
    "            self.batch_index = self.gen.batch_index\n",
    "            y = []\n",
    "            for i in y_gen:\n",
    "                if i == 0:\n",
    "                    leak_i = self.leak #*np.random.rand()\n",
    "                    y.append([leak_i, 1-leak_i])\n",
    "                else:             \n",
    "                    leak_i = self.leak*np.random.rand()\n",
    "                    y.append([1-leak_i, leak_i])\n",
    "            yield x, np.asarray(y, dtype='float32')\n",
    "    \n",
    "    def __next__(self):\n",
    "        return next(self.newGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def leakyLoss(pred, target):\n",
    "    return tf.reduce_mean(tf.losses.softmax_cross_entropy(pred, target, label_smoothing=0.01), name='cross_entropy')\n",
    "\n",
    "def getModel(dropout = 0.33, optimizer = 'adam', loss = leakyLoss):\n",
    "    baseModel = keras.applications.mobilenet.MobileNet(include_top=False, input_shape=(128, 128, 3), weights='imagenet')\n",
    "    x = baseModel.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=baseModel.inputs, outputs=x)\n",
    "\n",
    "    # multi GPU support not worth it, as bottleneck is in datagen-augmentation\n",
    "    # model = multi_gpu_model(model, gpus=3)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "    print(\"Created MobileNet Model with Dropout of {}\".format(dropout))\n",
    "    return model\n",
    "\n",
    "def trainModel(model, batchSize, modelName='model_weights', epochs=1):\n",
    "    global epochCounter\n",
    "    try:\n",
    "        epochCounter\n",
    "    except NameError:\n",
    "        epochCounter = 1\n",
    "    print(\"Start training for {} epochs with a batch size of {}. The overall current epoch is {}\".format(epochs, batchSize, epochCounter))\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        model.fit_generator(\n",
    "            trainBatches,\n",
    "            steps_per_epoch= trainBatches.n // batchSize,\n",
    "            epochs=1,\n",
    "            validation_data=validBatches,\n",
    "            validation_steps= validBatches.n // batchSize,\n",
    "            use_multiprocessing = True,\n",
    "            class_weight={1:25., 0:1.})\n",
    "        timeStamp = datetime.datetime.now().strftime(\"%y_%m_%d_%H_%M\")\n",
    "        fileName = \"{}_{}_epoch_{}.h5\".format(modelName, timeStamp, epochCounter)\n",
    "        epochCounter += 1\n",
    "        model.save_weights(os.path.join(modelOutputPath, fileName))\n",
    "        print(\"Done! Model Name is {}\".format(fileName))\n",
    "    return model, fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(dataGen, model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_predArr = []\n",
    "    files = []\n",
    "    rounds = dataGen.n // dataGen.batch_size \n",
    "    for i in range(rounds+1):\n",
    "        if i % (rounds//5+1) == 0:\n",
    "            print(\"{} of {} predictions\".format(len(y_predArr), dataGen.n))\n",
    "        x, y_t = next(dataGen)\n",
    "        y_p = model.predict(x, batch_size=dataGen.batch_size)\n",
    "        y_true.extend(y_t[:, 1])\n",
    "        y_predArr.extend(y_p[:, 1])\n",
    "        idx = (dataGen.batch_index - 1) * dataGen.batch_size\n",
    "        if dataGen.batch_index > 0:\n",
    "            idx = (dataGen.batch_index - 1) * dataGen.batch_size\n",
    "            files.extend(dataGen.filenames[idx : idx + dataGen.batch_size])\n",
    "        else:\n",
    "            files.extend(dataGen.filenames[0 : len(y_p)])\n",
    "    print(\"{} of {} predictions\".format(len(y_predArr), dataGen.n))\n",
    "    for i in y_predArr:\n",
    "        y_pred.append(i)\n",
    "    return np.asarray(y_true), np.asarray(y_pred), np.asarray(files)\n",
    "\n",
    "def showErrors(y_pred, y_true, basicPath, threshold=0.5, mode='fn'):\n",
    "    if mode == 'fp':\n",
    "        print(\"\\nFalse positives:\\n\")\n",
    "        maskParam = True\n",
    "    elif mode == 'fn':\n",
    "        print(\"\\nFalse negatives\\n\")\n",
    "        maskParam = False  \n",
    "    test = (y_pred > (1-threshold)).astype(int)\n",
    "    mask = np.where((y_true == int(maskParam)) & (test == int(not maskParam)))[0]\n",
    "    falsePositives = fileNames[mask]\n",
    "    probs = y_pred[mask]\n",
    "    print(probs)\n",
    "    pathsFalsePositives = [os.path.join(basicPath, f) for f in falsePositives]\n",
    "    print(pathsFalsePositives[:10])\n",
    "    i = 0\n",
    "    for f, p in zip(pathsFalsePositives, probs):\n",
    "        i += 1\n",
    "        if i == 25:\n",
    "            break\n",
    "        print(\"{}. {}: {}\".format(i, f, p))\n",
    "        plt.figure()\n",
    "        plt.title(\"Filename: {} \\nProbability: {}\".format(os.path.basename(f), p))\n",
    "        plt.imshow(plt.imread(f), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "def getConfusionMatrix(thresholds, y_pred, y_true):\n",
    "    for thres in thresholds:\n",
    "        curr_pred = (y_pred > thres).astype(int)\n",
    "        print(\"Cofusion matrix for {} threshold\".format(thres))\n",
    "        print(confusion_matrix(y_true, curr_pred))\n",
    "        \n",
    "def predictSpecificImage(imgPath):\n",
    "    img = load_img(imgPath)  # this is a PIL image\n",
    "    # import pdb; pdb.set_trace()\n",
    "    img = img.resize((128,128))\n",
    "    imgname, _ = os.path.splitext(os.path.basename(imgPath))\n",
    "    x = img_to_array(img)  \n",
    "    x = x/255 #rescale\n",
    "    plt.imshow(x)\n",
    "    x = x.reshape((1,) + x.shape)  \n",
    "    print(x.shape)\n",
    "    result = model.predict(x)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = '/home/../train'\n",
    "validPath = '/home/../valid'\n",
    "modelOutputPath = '/home/../model_weights'\n",
    "modelName = 'model_we._data'\n",
    "if not os.path.exists(modelOutputPath):\n",
    "    os.makedirs(modelOutputPath)\n",
    "batchSize = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All that is needed to generically train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "trainBatches, validBatches = getBatchGens(trainPath, validPath, batchSize)\n",
    "trainBatches = leakyBatches(trainBatches, leak=0)\n",
    "validBatches = leakyBatches(validBatches, leak=0)\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model = getModel(optimizer=adam, dropout=0)\n",
    "model, fileName = trainModel(model, batchSize, modelName=modelName, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '.h5'\n",
    "trainBatches, validBatches = getBatchGens(trainPath, validPath, batchSize)\n",
    "trainBatches = leakyBatches(trainBatches, leak=0)\n",
    "validBatches = leakyBatches(validBatches, leak=0)\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model = getModel(optimizer=adam, dropout=0)\n",
    "model.load_weights(os.path.join(modelOutputPath, fileName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it's done with tensorflow training!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is important, so that tensors of Keras are initialized for tensorflow to use!\n",
    "sess = K.get_session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Keras model, add loss and train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.layers import InputLayer\n",
    "from keras import backend as K\n",
    "\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "weight_test = [v for v in tf.trainable_variables() if v.name =='conv1_bn_1/beta:0']\n",
    "\n",
    "img = tf.placeholder(shape=(None, 128, 128,3), dtype=tf.float32)\n",
    "#img = keras.Input(shape=(128, 128,3), dtype=tf.float32)\n",
    "baseModel = keras.applications.mobilenet.MobileNet(include_top=False, input_shape=(128, 128, 3), weights='imagenet')\n",
    "\n",
    "x = baseModel(img)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.8)(x)\n",
    "preds = Dense(2, activation=None)(x)\n",
    "loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(labels, preds))\n",
    "#  train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize uninitialized keras variables\n",
    "uninitialized_variables_names = sess.run(tf.report_uninitialized_variables(tf.global_variables()))\n",
    "uninitialized_variables_names = [name.decode(\"utf-8\") for name in uninitialized_variables_names]\n",
    "uninitialized_variables = [v for v in tf.global_variables() if v.name[:-2] in uninitialized_variables_names]\n",
    "init = tf.variables_initializer(uninitialized_variables)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [op for op in sess.graph.get_operations() if 'dropout' in op.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'dropout_1/cond/Switch' type=Switch>,\n",
       " <tf.Operation 'dropout_1/cond/switch_t' type=Identity>,\n",
       " <tf.Operation 'dropout_1/cond/switch_f' type=Identity>,\n",
       " <tf.Operation 'dropout_1/cond/pred_id' type=Identity>,\n",
       " <tf.Operation 'dropout_1/cond/mul/y' type=Const>,\n",
       " <tf.Operation 'dropout_1/cond/mul/Switch' type=Switch>,\n",
       " <tf.Operation 'dropout_1/cond/mul' type=Mul>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/keep_prob' type=Const>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/Shape' type=Shape>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/random_uniform' type=Add>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/add' type=Add>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/Floor' type=Floor>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/div' type=RealDiv>,\n",
       " <tf.Operation 'dropout_1/cond/dropout/mul' type=Mul>,\n",
       " <tf.Operation 'dropout_1/cond/Switch_1' type=Switch>,\n",
       " <tf.Operation 'dropout_1/cond/Merge' type=Merge>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/Merge_grad/cond_grad' type=Switch>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/Merge_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/Merge_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/Merge_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/Switch_1_grad/cond_grad' type=Merge>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/mul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/RealDiv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/RealDiv_1' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/RealDiv_2' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/dropout/div_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/cond/mul/Switch_grad/cond_grad' type=Merge>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_test = [v for v in tf.trainable_variables() if v.name[:6] =='dense_'[:8]]\n",
    "print(weight_test)\n",
    "with sess.as_default():\n",
    "    sanityCheck = sess.run(weight_test)\n",
    "    print([v.name for v in weight_test])\n",
    "    print(sanityCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "iterations_per_epoch = int(trainBatches.n/trainBatches.batch_size + 0.5)\n",
    "print(iterations_per_epoch)\n",
    "batch = next(trainBatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    pred = sess.run(preds, feed_dict={img: batch[0],\n",
    "                             labels: batch[1]})\n",
    "print(pred, batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(trainBatches.newGen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.metrics import categorical_accuracy as accuracy\n",
    "def categorical_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.cast(K.equal(K.argmax(y_true, axis=-1),\n",
    "                          K.argmax(y_pred, axis=-1)),\n",
    "                  K.floatx()))\n",
    "acc_value = categorical_accuracy(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102182 images belonging to 2 classes.\n",
      "Found 25760 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainBatches, validBatches = getBatchGens(trainPath, validPath, batchSize)\n",
    "trainBatches = leakyBatches(trainBatches, leak=0)\n",
    "validBatches = leakyBatches(validBatches, leak=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = 1\n",
    "with sess.as_default():\n",
    "    for i in range(iterations_per_epoch*3):\n",
    "        batch = next(trainBatches)\n",
    "        sanityCheck = sess.run(weight_test)\n",
    "        loss_val1 = sess.run(loss, feed_dict={img: batch[0],\n",
    "                             labels: batch[1],\n",
    "                                K.learning_phase(): train})\n",
    "        loss_val11 = sess.run(loss, feed_dict={img: batch[0],\n",
    "                             labels: batch[1],\n",
    "                                K.learning_phase(): 0})\n",
    "        acc_val1 = acc_value.eval(feed_dict={img: batch[0],\n",
    "                                    labels:batch[1]})\n",
    "        pred = sess.run(preds, feed_dict={img: batch[0],\n",
    "                             labels: batch[1], # })\n",
    "                                 K.learning_phase(): train})\n",
    "        # print(\"Iteration {}, loss_val1: {}\".format(i+1, loss_val1), end='\\r')\n",
    "        train_step.run(feed_dict={img: batch[0],\n",
    "                                 labels: batch[1], # })\n",
    "                                 K.learning_phase(): train})\n",
    "        loss_val2 = sess.run(loss, feed_dict={img: batch[0],\n",
    "                                 labels: batch[1], # })\n",
    "                                 K.learning_phase(): train})\n",
    "        print(\"Iteration {}, acc_val1: {},  loss_val1: {} {}\".format(i+1, acc_val1, loss_val1, loss_val11), \"Iteration {}, loss_val2: {}\".format(i+1, loss_val2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "acc_value = accuracy(labels, preds)\n",
    "with sess.as_default():\n",
    "    print acc_value.eval(feed_dict={img: batch[0],\n",
    "                                    labels:batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = keras.applications.mobilenet.MobileNet(include_top=False, input_shape=(128, 128, 3), weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = keras.applications.mobilenet.MobileNet(include_top=False, input_shape=(128, 128, 3), weights='imagenet')\n",
    "x = baseModel.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(dropout)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=baseModel.inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pathImageSet = 'folder'\n",
    "datagenExtraTest = ImageDataGenerator()\n",
    "extraTestBatches = datagenExtraTest.flow_from_directory(\n",
    "        pathImageSet,  # this is the target directory\n",
    "        target_size=(1200, 1600),  # all images will be resized to 150x150\n",
    "        batch_size=batchSize,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)  # since we use binary_crossentropy loss, we need binary labels\n",
    "# get predictions\n",
    "# validBatches needs to be initialized again, so we get the correct filenames\n",
    "extraTestBatches = leakyBatches(extraTestBatches, leak = 0)\n",
    "y_true, y_pred, fileNames = getPredictionsSegment(extraTestBatches, model)\n",
    "# Show confusion matrix for various thresholds\n",
    "thresholds = [0.5, 0.1, 0.04, 0.004, 0.001]\n",
    "getConfusionMatrix(thresholds, y_pred, y_true)\n",
    "# show up to 25 false positives\n",
    "showErrors(y_pred, y_true, basicPath = pathImageSet, threshold=0.5, mode='fp')\n",
    "# show up to 25 false negatives\n",
    "showErrors(y_pred, y_true, basicPath = pathImageSet, threshold=0.5, mode='fn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictSpecificImage2Segment('x.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
